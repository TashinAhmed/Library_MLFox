{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Finetuning Basenets.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TashinAhmed/Various-Architectures-of-Convolutional-Networks/blob/master/Finetuning_Basenets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymTxoTt_So6h",
        "colab_type": "text"
      },
      "source": [
        "#Model\n",
        "From Keras, we can easily use some image classification models.\n",
        "\n",
        "Xception, VGG16, VGG19, ResNet50, InceptionV3\n",
        "\n",
        "more on http://marubon-ds.blogspot.com/2017/09/vgg-fine-tuning-model.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIEzlO0fS7NJ",
        "colab_type": "text"
      },
      "source": [
        "#import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoWkRmeLScqD",
        "colab_type": "code",
        "outputId": "b07a5bbc-e931-4e6d-9ef9-2ee268d0e6fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "import random\n",
        "import cv2\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.optimizers import SGD\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.xception import Xception\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljHsHlp6TCAD",
        "colab_type": "text"
      },
      "source": [
        "#making data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18VZRqlCS__e",
        "colab_type": "code",
        "outputId": "02e6c1dd-c6c7-447d-bda3-0f5c2e6a0766",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# read data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# limit the amount of the data\n",
        "# train data\n",
        "ind_train = random.sample(list(range(x_train.shape[0])), 1000)\n",
        "x_train = x_train[ind_train]\n",
        "y_train = y_train[ind_train]\n",
        "\n",
        "# test data\n",
        "ind_test = random.sample(list(range(x_test.shape[0])), 1000)\n",
        "x_test = x_test[ind_test]\n",
        "y_test = y_test[ind_test]\n",
        "\n",
        "def resize_data(data):\n",
        "    data_upscaled = np.zeros((data.shape[0], 320, 320, 3))\n",
        "    for i, img in enumerate(data):\n",
        "        large_img = cv2.resize(img, dsize=(320, 320), interpolation=cv2.INTER_CUBIC)\n",
        "        data_upscaled[i] = large_img\n",
        "\n",
        "    return data_upscaled\n",
        "\n",
        "# resize train and  test data\n",
        "x_train_resized = resize_data(x_train)\n",
        "x_test_resized = resize_data(x_test)\n",
        "\n",
        "# make explained variable hot-encoded\n",
        "y_train_hot_encoded = to_categorical(y_train)\n",
        "y_test_hot_encoded = to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gvdr5IqYTKkC",
        "colab_type": "text"
      },
      "source": [
        "#setting model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qzYysPcTMbS",
        "colab_type": "code",
        "outputId": "2ba42e73-9dbf-4e9c-fe05-1417500688b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        }
      },
      "source": [
        "def model(x_train, y_train, base_model):\n",
        "\n",
        "    # get layers and add average pooling layer\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    # add fully-connected layer\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    # add output layer\n",
        "    predictions = Dense(10, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "# -------------------------------------------------------------------------------\n",
        "    # freeze pre-trained model area's layer\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # update the weight that are added\n",
        "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "    model.fit(x_train, y_train)\n",
        "# -------------------------------------------------------------------------------\n",
        "    # choose the layers which are updated by training\n",
        "    layer_num = len(model.layers)\n",
        "    for layer in model.layers[:int(layer_num * 0.9)]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    for layer in model.layers[int(layer_num * 0.9):]:\n",
        "        layer.trainable = True\n",
        "\n",
        "    # update the weights\n",
        "    model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    history = model.fit(x_train, y_train, epochs=5)\n",
        "    return history\n",
        "\n",
        "inception_model = InceptionV3(weights='imagenet', include_top=False)\n",
        "res_50_model = ResNet50(weights='imagenet', include_top=False)\n",
        "vgg_19_model = VGG19(weights='imagenet', include_top=False)\n",
        "vgg_16_model = VGG16(weights='imagenet', include_top=False)\n",
        "xception_model = Xception(weights='imagenet', include_top=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0806 19:47:51.575990 140395060819840 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0806 19:47:51.623878 140395060819840 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0806 19:47:51.632300 140395060819840 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0806 19:47:51.682504 140395060819840 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0806 19:47:51.683752 140395060819840 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0806 19:47:51.999335 140395060819840 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0806 19:47:52.358646 140395060819840 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0806 19:47:53.054952 140395060819840 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94658560/94653016 [==============================] - 1s 0us/step\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 1s 0us/step\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leRYL_ojTh5Y",
        "colab_type": "text"
      },
      "source": [
        "#evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LHNmsI0UG5k",
        "colab_type": "code",
        "outputId": "1dd77094-8a28-41db-afba-5e0f5d459360",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        }
      },
      "source": [
        "history_inception_v3 = model(x_train_resized, y_train_hot_encoded, inception_model)\n",
        "history_res_50 = model(x_train_resized, y_train_hot_encoded, res_50_model)\n",
        "history_vgg_19 = model(x_train_resized, y_train_hot_encoded, vgg_19_model)\n",
        "history_vgg_16 = model(x_train_resized, y_train_hot_encoded, vgg_16_model)\n",
        "history_xception = model(x_train_resized, y_train_hot_encoded, xception_model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0806 19:48:36.038173 140395060819840 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0806 19:48:36.176939 140395060819840 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-TIiHTpTi-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check accuracy\n",
        "evaluation_inception_v3 = history_inception_v3.model.evaluate(x_test_resized,y_test_hot_encoded)\n",
        "evaluation_res_50 = history_res_50.model.evaluate(x_test_resized,y_test_hot_encoded)\n",
        "evaluation_vgg_19 = history_vgg_19.model.evaluate(x_test_resized,y_test_hot_encoded)\n",
        "evaluation_vgg_16 = history_vgg_16.model.evaluate(x_test_resized,y_test_hot_encoded)\n",
        "evaluation_xception = history_xception.model.evaluate(x_test_resized,y_test_hot_encoded)\n",
        "\n",
        "print(\"inception_v3:{}\".format(evaluation_inception_v3))\n",
        "print(\"res_50:{}\".format(evaluation_res_50))\n",
        "print(\"vgg_19:{}\".format(evaluation_vgg_19))\n",
        "print(\"vgg_16:{}\".format(evaluation_vgg_16))\n",
        "print(\"xception:{}\".format(evaluation_xception))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCTXQuI_Zh1T",
        "colab_type": "text"
      },
      "source": [
        " OUTCOME\n",
        " \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        " inception_v3:[1.5071683092117309, 0.622]\n",
        "\n",
        " res_50:[1.324682321548462, 0.55100000000000005]\n",
        " \n",
        " vgg_19:[1.0588858013153075, 0.63600000000000001]\n",
        " \n",
        " vgg_16:[2.7452965526580813, 0.57899999999999996]\n",
        " \n",
        " xception:[0.89050176906585699, 0.70999999999999996]"
      ]
    }
  ]
}